{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#准备数据\n",
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)\n",
    "print(x_train.min(),x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将数据转化为tensor格式可以使用GPU加速\n",
    "x_train = tf.convert_to_tensor(x_train,dtype=tf.float32)/255.#数据归一化\n",
    "y_train = tf.convert_to_tensor(y_train,dtype=tf.int32)\n",
    "set(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "#将y转化为one-hot编码\n",
    "y_train = tf.one_hot(y_train,depth=10)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 28, 28), (None, 10)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "#每次训练喂入一个batch\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(200)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#准备网络结构和优化器。\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(784,activation='relu'),\n",
    "    keras.layers.Dense(256,activation='relu'),\n",
    "    keras.layers.Dense(10)])\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001)#使用随机梯度下降进行优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch):\n",
    "    for step,(x,y) in enumerate(train_data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            x = tf.reshape(x,(-1,28*28))#打平数据[b,28,28]=>[b,784]\n",
    "            out = model(x)#将数据喂入模型，前向传播，[b,784]=>[b,10]\n",
    "            loss =tf.reduce_sum(tf.square(out-y))/x.shape[0]#损失函数为均方误差\n",
    "        grad = tape.gradient(loss,model.trainable_variables)#计算各个参数的梯度\n",
    "        optimizer.apply_gradients(zip(grad, model.trainable_variables))#通过随机梯度下降更新参数\n",
    "        if step % 100 == 0:\n",
    "            print(\"数据集迭代第 %s 次, 训练step为 %s, loss函数为：%s\"%(epoch,step,loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集迭代第 0 次, 训练step为 0, loss函数为：1.9786569\n",
      "数据集迭代第 0 次, 训练step为 100, loss函数为：0.9430006\n",
      "数据集迭代第 0 次, 训练step为 200, loss函数为：0.7058045\n",
      "数据集迭代第 1 次, 训练step为 0, loss函数为：0.65560806\n",
      "数据集迭代第 1 次, 训练step为 100, loss函数为：0.6878572\n",
      "数据集迭代第 1 次, 训练step为 200, loss函数为：0.5512156\n",
      "数据集迭代第 2 次, 训练step为 0, loss函数为：0.5389582\n",
      "数据集迭代第 2 次, 训练step为 100, loss函数为：0.59870124\n",
      "数据集迭代第 2 次, 训练step为 200, loss函数为：0.48603183\n",
      "数据集迭代第 3 次, 训练step为 0, loss函数为：0.4805463\n",
      "数据集迭代第 3 次, 训练step为 100, loss函数为：0.5472573\n",
      "数据集迭代第 3 次, 训练step为 200, loss函数为：0.4461216\n",
      "数据集迭代第 4 次, 训练step为 0, loss函数为：0.44239762\n",
      "数据集迭代第 4 次, 训练step为 100, loss函数为：0.51197726\n",
      "数据集迭代第 4 次, 训练step为 200, loss函数为：0.41766468\n",
      "数据集迭代第 5 次, 训练step为 0, loss函数为：0.41463417\n",
      "数据集迭代第 5 次, 训练step为 100, loss函数为：0.485101\n",
      "数据集迭代第 5 次, 训练step为 200, loss函数为：0.39556026\n",
      "数据集迭代第 6 次, 训练step为 0, loss函数为：0.39277324\n",
      "数据集迭代第 6 次, 训练step为 100, loss函数为：0.46321744\n",
      "数据集迭代第 6 次, 训练step为 200, loss函数为：0.3778201\n",
      "数据集迭代第 7 次, 训练step为 0, loss函数为：0.37480026\n",
      "数据集迭代第 7 次, 训练step为 100, loss函数为：0.44495872\n",
      "数据集迭代第 7 次, 训练step为 200, loss函数为：0.3630118\n",
      "数据集迭代第 8 次, 训练step为 0, loss函数为：0.35962403\n",
      "数据集迭代第 8 次, 训练step为 100, loss函数为：0.4293762\n",
      "数据集迭代第 8 次, 训练step为 200, loss函数为：0.3500811\n",
      "数据集迭代第 9 次, 训练step为 0, loss函数为：0.34652394\n",
      "数据集迭代第 9 次, 训练step为 100, loss函数为：0.41580558\n",
      "数据集迭代第 9 次, 训练step为 200, loss函数为：0.33865556\n",
      "数据集迭代第 10 次, 训练step为 0, loss函数为：0.33509582\n",
      "数据集迭代第 10 次, 训练step为 100, loss函数为：0.40385005\n",
      "数据集迭代第 10 次, 训练step为 200, loss函数为：0.3284837\n",
      "数据集迭代第 11 次, 训练step为 0, loss函数为：0.32500038\n",
      "数据集迭代第 11 次, 训练step为 100, loss函数为：0.39317054\n",
      "数据集迭代第 11 次, 训练step为 200, loss函数为：0.31948134\n",
      "数据集迭代第 12 次, 训练step为 0, loss函数为：0.3158181\n",
      "数据集迭代第 12 次, 训练step为 100, loss函数为：0.3832866\n",
      "数据集迭代第 12 次, 训练step为 200, loss函数为：0.31118077\n",
      "数据集迭代第 13 次, 训练step为 0, loss函数为：0.30743888\n",
      "数据集迭代第 13 次, 训练step为 100, loss函数为：0.37422034\n",
      "数据集迭代第 13 次, 训练step为 200, loss函数为：0.30360737\n",
      "数据集迭代第 14 次, 训练step为 0, loss函数为：0.29985958\n",
      "数据集迭代第 14 次, 训练step为 100, loss函数为：0.36583304\n",
      "数据集迭代第 14 次, 训练step为 200, loss函数为：0.2966956\n",
      "数据集迭代第 15 次, 训练step为 0, loss函数为：0.2929972\n",
      "数据集迭代第 15 次, 训练step为 100, loss函数为：0.3580484\n",
      "数据集迭代第 15 次, 训练step为 200, loss函数为：0.2903705\n",
      "数据集迭代第 16 次, 训练step为 0, loss函数为：0.28660363\n",
      "数据集迭代第 16 次, 训练step为 100, loss函数为：0.3508531\n",
      "数据集迭代第 16 次, 训练step为 200, loss函数为：0.28445676\n",
      "数据集迭代第 17 次, 训练step为 0, loss函数为：0.28074992\n",
      "数据集迭代第 17 次, 训练step为 100, loss函数为：0.34414917\n",
      "数据集迭代第 17 次, 训练step为 200, loss函数为：0.2790358\n",
      "数据集迭代第 18 次, 训练step为 0, loss函数为：0.2753402\n",
      "数据集迭代第 18 次, 训练step为 100, loss函数为：0.33788383\n",
      "数据集迭代第 18 次, 训练step为 200, loss函数为：0.2739932\n",
      "数据集迭代第 19 次, 训练step为 0, loss函数为：0.2701813\n",
      "数据集迭代第 19 次, 训练step为 100, loss函数为：0.33199883\n",
      "数据集迭代第 19 次, 训练step为 200, loss函数为：0.26926148\n",
      "数据集迭代第 20 次, 训练step为 0, loss函数为：0.2653136\n",
      "数据集迭代第 20 次, 训练step为 100, loss函数为：0.3264711\n",
      "数据集迭代第 20 次, 训练step为 200, loss函数为：0.26484296\n",
      "数据集迭代第 21 次, 训练step为 0, loss函数为：0.26075456\n",
      "数据集迭代第 21 次, 训练step为 100, loss函数为：0.3212477\n",
      "数据集迭代第 21 次, 训练step为 200, loss函数为：0.26066738\n",
      "数据集迭代第 22 次, 训练step为 0, loss函数为：0.25648046\n",
      "数据集迭代第 22 次, 训练step为 100, loss函数为：0.3162972\n",
      "数据集迭代第 22 次, 训练step为 200, loss函数为：0.25671008\n",
      "数据集迭代第 23 次, 训练step为 0, loss函数为：0.2524492\n",
      "数据集迭代第 23 次, 训练step为 100, loss函数为：0.31159085\n",
      "数据集迭代第 23 次, 训练step为 200, loss函数为：0.2529673\n",
      "数据集迭代第 24 次, 训练step为 0, loss函数为：0.2486265\n",
      "数据集迭代第 24 次, 训练step为 100, loss函数为：0.30717355\n",
      "数据集迭代第 24 次, 训练step为 200, loss函数为：0.2494855\n",
      "数据集迭代第 25 次, 训练step为 0, loss函数为：0.24498837\n",
      "数据集迭代第 25 次, 训练step为 100, loss函数为：0.30296057\n",
      "数据集迭代第 25 次, 训练step为 200, loss函数为：0.24618532\n",
      "数据集迭代第 26 次, 训练step为 0, loss函数为：0.2415762\n",
      "数据集迭代第 26 次, 训练step为 100, loss函数为：0.2989781\n",
      "数据集迭代第 26 次, 训练step为 200, loss函数为：0.24305262\n",
      "数据集迭代第 27 次, 训练step为 0, loss函数为：0.23836686\n",
      "数据集迭代第 27 次, 训练step为 100, loss函数为：0.29520646\n",
      "数据集迭代第 27 次, 训练step为 200, loss函数为：0.24013084\n",
      "数据集迭代第 28 次, 训练step为 0, loss函数为：0.235318\n",
      "数据集迭代第 28 次, 训练step为 100, loss函数为：0.2916378\n",
      "数据集迭代第 28 次, 训练step为 200, loss函数为：0.23734541\n",
      "数据集迭代第 29 次, 训练step为 0, loss函数为：0.23241247\n",
      "数据集迭代第 29 次, 训练step为 100, loss函数为：0.28823385\n",
      "数据集迭代第 29 次, 训练step为 200, loss函数为：0.23470497\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    train_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
