{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 80) (25000,) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "(25000, 80) (25000,)\n",
      "(128, 80)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "totals_words = 10000#只使用最常用的前10000个单词\n",
    "embedding_len = 100#每个单词的维度为100\n",
    "max_review_len = 80#每个句子的长度\n",
    "batch_size = 128\n",
    "(x_train,y_train),(x_val,y_val) = keras.datasets.imdb.load_data(num_words=totals_words)#只使用最常用的10000个单词，其他单词标记为未知\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,maxlen=max_review_len)#设置每个句子的长度为80\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val,maxlen=max_review_len)\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(10000).batch(batch_size,drop_remainder=True)\n",
    "db_val = tf.data.Dataset.from_tensor_slices((x_val,y_val)).shuffle(1000).batch(batch_size,drop_remainder=True)#最后一个batch长度不够将其drop\n",
    "\n",
    "db_iter = iter(db_train)\n",
    "sample = next(db_iter)\n",
    "print(x_train.shape,y_train.shape,tf.reduce_max(y_train),tf.reduce_min(y_train))\n",
    "print(x_val.shape,y_val.shape)\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRnn(keras.Model):\n",
    "    def __init__(self,units):\n",
    "        super(MyRnn,self).__init__()\n",
    "        #[b,80]=>[b,80,100]\n",
    "        self.embedding = layers.Embedding(input_dim=totals_words,output_dim=embedding_len,input_length=max_review_len)\n",
    "        \n",
    "        #[b,80]=>[b,units]\n",
    "        self.rnn_cell0 = layers.LSTM(units,return_sequences=True,dropout=0.5,unroll=True)#返回输出序列中的最后一个输出\n",
    "        self.rnn_cell1 = layers.LSTM(units,dropout=0.5,unroll=True)#unroll 是否展开网络\n",
    "        #[b,units]=>[b,1]\n",
    "        self.fc = layers.Dense(1)\n",
    "        \n",
    "    def call(self,inputs,training=None):\n",
    "        #x = [b,80]\n",
    "        x = inputs\n",
    "        #[b,80]=>[b,80,100]\n",
    "        x = self.embedding(x)\n",
    "        #[b,80]=>[b,64]\n",
    "        x = self.rnn_cell0(x)\n",
    "        x = self.rnn_cell1(x)\n",
    "        #[b,64]=>[b,1]\n",
    "        out = self.fc(x)\n",
    "        #p(y is positive|x)\n",
    "        pred = tf.sigmoid(out)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0824 19:52:46.818736  6080 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x000001DE6B301828>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "W0824 19:52:46.823687  6080 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x000001DE6B301F28>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "195/195 [==============================] - 152s 781ms/step - loss: 0.6186 - accuracy: 0.5495 - val_loss: 0.4494 - val_accuracy: 0.7901\n",
      "Epoch 2/5\n",
      "195/195 [==============================] - 49s 249ms/step - loss: 0.4133 - accuracy: 0.7969 - val_loss: 0.3905 - val_accuracy: 0.8240\n",
      "Epoch 3/5\n",
      "195/195 [==============================] - 48s 247ms/step - loss: 0.3417 - accuracy: 0.8516 - val_loss: 0.3829 - val_accuracy: 0.8322\n",
      "Epoch 4/5\n",
      "195/195 [==============================] - 48s 246ms/step - loss: 0.3057 - accuracy: 0.8709 - val_loss: 0.3882 - val_accuracy: 0.8332\n",
      "Epoch 5/5\n",
      "195/195 [==============================] - 51s 262ms/step - loss: 0.2783 - accuracy: 0.8894 - val_loss: 0.3857 - val_accuracy: 0.8346\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    units = 64\n",
    "    model = MyRnn(units)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(0.0002),loss=tf.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "    model.fit(db_train,epochs=5,validation_data=db_val)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
