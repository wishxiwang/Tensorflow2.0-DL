{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_val,y_val)=keras.datasets.cifar10.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float64)/255.-0.5\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 32, 32, 3) (200, 1)\n"
     ]
    }
   ],
   "source": [
    "db_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(200).map(preprocess).shuffle(10000)\n",
    "db_val = tf.data.Dataset.from_tensor_slices((x_val,y_val)).batch(200).map(preprocess).shuffle(10000)\n",
    "\n",
    "db_iter = iter(db_train)\n",
    "sample=next(db_iter)\n",
    "print(sample[0].shape,sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入参数初始化、batchnorm、dropout\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32,kernel_size=[3,3],padding='same',kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                        kernel_initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=0.05),bias_initializer=tf.initializers.zeros),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(64,kernel_size=[3,3],padding='same',kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                        kernel_initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=0.05),bias_initializer=tf.initializers.zeros),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(128,kernel_size=[3,3],padding='same',kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                        kernel_initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=0.05),bias_initializer=tf.initializers.zeros),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(256,kernel_size=[3,3],padding='same',kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                        kernel_initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=0.05),bias_initializer=tf.initializers.zeros),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(256,kernel_size=[3,3],padding='same',kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                        kernel_initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=0.05),bias_initializer=tf.initializers.zeros),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(512,kernel_size=[3,3],padding='same',kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                        kernel_initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=0.05),bias_initializer=tf.initializers.zeros),\n",
    "    keras.layers.Dropout(0.6),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512,activation=tf.nn.relu,kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                        kernel_initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=0.05),bias_initializer=tf.initializers.zeros),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(128,activation=tf.nn.relu,kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                        kernel_initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=0.05),bias_initializer=tf.initializers.zeros),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10,activation=tf.nn.softmax,\n",
    "                        kernel_initializer=tf.initializers.TruncatedNormal(mean=0.0, stddev=0.05),bias_initializer=tf.initializers.zeros)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 37s 149ms/step - loss: 3.2504 - accuracy: 0.3975 - val_loss: 2.7906 - val_accuracy: 0.2125\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 1.8368 - accuracy: 0.5394 - val_loss: 1.8254 - val_accuracy: 0.5636\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 1.6691 - accuracy: 0.6106 - val_loss: 1.7730 - val_accuracy: 0.5740\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 1.5910 - accuracy: 0.6442 - val_loss: 1.6326 - val_accuracy: 0.6241\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 1.5134 - accuracy: 0.6808 - val_loss: 1.5644 - val_accuracy: 0.6625\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 1.4493 - accuracy: 0.7096 - val_loss: 1.4255 - val_accuracy: 0.7032\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 1.3985 - accuracy: 0.7279 - val_loss: 1.4612 - val_accuracy: 0.6992\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 1.3618 - accuracy: 0.7479 - val_loss: 1.4801 - val_accuracy: 0.7025\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 1.3336 - accuracy: 0.7614 - val_loss: 1.4738 - val_accuracy: 0.7085\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 1.2979 - accuracy: 0.7809 - val_loss: 1.4388 - val_accuracy: 0.7278\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 1.2746 - accuracy: 0.7953 - val_loss: 1.5058 - val_accuracy: 0.7165\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 1.2498 - accuracy: 0.8068 - val_loss: 1.5271 - val_accuracy: 0.7126\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 1.2215 - accuracy: 0.8180 - val_loss: 1.5508 - val_accuracy: 0.7192\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 1.2035 - accuracy: 0.8329 - val_loss: 1.6345 - val_accuracy: 0.6993\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 1.1795 - accuracy: 0.8433 - val_loss: 1.5858 - val_accuracy: 0.7215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d6f808f470>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_optimizer = keras.optimizers.SGD(learning_rate=0.1,decay=0.005,momentum=0.9)#学习率衰减和滑动平均\n",
    "model.compile(optimizer=my_optimizer,loss=tf.losses.sparse_categorical_crossentropy,metrics=['accuracy'])\n",
    "callback = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, mode='auto')#提前停止\n",
    "]\n",
    "model.fit(db_train,epochs=50,validation_data=db_val,validation_freq=1,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 23ms/step - loss: 1.5858 - accuracy: 0.7215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5858200550079347, 0.7215]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
