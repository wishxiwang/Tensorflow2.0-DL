{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_val,y_val) = keras.datasets.cifar10.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义残差块\n",
    "#每个残差块包括两个卷积层\n",
    "class BasicBlock(keras.Model):\n",
    "    def __init__(self,filter_num,stride = 1):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        #padding为same保证输出的size为输入的size整除strides后得到的\n",
    "        self.conv1 = keras.layers.Conv2D(filters=filter_num,kernel_size=(3,3),strides=stride,padding='same')\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2 = keras.layers.Conv2D(filters=filter_num,kernel_size=(3,3),strides=1,padding='same')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        \n",
    "        #残差块的输入经过卷积层以后，输出的size可能发生改变，为了保证size一致从而能相加，\n",
    "        if stride!=1:#当步长不为1时，size改变\n",
    "            self.downsample = keras.Sequential()\n",
    "            self.downsample.add(keras.layers.Conv2D(filters=filter_num,kernel_size=(1,1),strides=stride))\n",
    "        else:#如果为1，size没有改变，原样输出\n",
    "            self.downsample = lambda x:x\n",
    "    \n",
    "    def call(self,inputs,traing=None):\n",
    "        out = self.conv1(inputs)\n",
    "        out = self.bn1(out)\n",
    "        out = keras.activations.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        identity = self.downsample(inputs)#调整维度\n",
    "        \n",
    "        out = keras.layers.add([out,identity])#恒等映射\n",
    "        \n",
    "        return keras.activations.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    input = keras.layers.Input(shape=[32,32,3])\n",
    "    x = tf.keras.layers.Conv2D(64, 3 , strides=1, padding='same', activation=\"relu\",kernel_initializer=initializers.he_uniform())(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    for filter_num in [64,64,128,128,256,256,512,512]:#8个残差块，每个残差块2个卷积，一共16层\n",
    "        x = BasicBlock(filter_num,2)(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    out = layers.Dense(10, activation=tf.nn.softmax)(x)\n",
    "    model = keras.models.Model(inputs=input, outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(0.01),loss=tf.losses.sparse_categorical_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入数据增强\n",
    "datagen = ImageDataGenerator( \n",
    "            rotation_range=20, #图片随机转动的角度\n",
    "            width_shift_range=0.2, #图片水平偏移的幅度\n",
    "            height_shift_range=0.2, #图片竖直偏移的幅度\n",
    "            horizontal_flip=True,#进行随机水平翻转\n",
    "            validation_split=0.13)# 保留用于验证的图像的比例（严格在0和1之间)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "782/782 [==============================] - 109s 139ms/step - loss: 1.9779 - accuracy: 0.2492 - val_loss: 2.9492 - val_accuracy: 0.1593\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 81s 104ms/step - loss: 1.7015 - accuracy: 0.3540 - val_loss: 1.9921 - val_accuracy: 0.3285\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 82s 105ms/step - loss: 1.5588 - accuracy: 0.4155 - val_loss: 1.5995 - val_accuracy: 0.4273\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 83s 106ms/step - loss: 1.4485 - accuracy: 0.4653 - val_loss: 1.3968 - val_accuracy: 0.4922\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 83s 106ms/step - loss: 1.3316 - accuracy: 0.5197 - val_loss: 1.3762 - val_accuracy: 0.5234\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 83s 106ms/step - loss: 1.2489 - accuracy: 0.5551 - val_loss: 1.5620 - val_accuracy: 0.4893\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 83s 106ms/step - loss: 1.1768 - accuracy: 0.5863 - val_loss: 1.6537 - val_accuracy: 0.4992\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 84s 107ms/step - loss: 1.1338 - accuracy: 0.6007 - val_loss: 1.0723 - val_accuracy: 0.6221\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 1.1032 - accuracy: 0.6162 - val_loss: 1.3233 - val_accuracy: 0.5827\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 1.0509 - accuracy: 0.6345 - val_loss: 1.1634 - val_accuracy: 0.6034\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 1.0192 - accuracy: 0.6439 - val_loss: 1.2413 - val_accuracy: 0.5795\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 0.9956 - accuracy: 0.6536 - val_loss: 1.1946 - val_accuracy: 0.6057\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.9728 - accuracy: 0.6650 - val_loss: 1.1219 - val_accuracy: 0.6352\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 87s 111ms/step - loss: 0.9405 - accuracy: 0.6758 - val_loss: 1.1037 - val_accuracy: 0.6409\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 0.9575 - accuracy: 0.6723 - val_loss: 1.0995 - val_accuracy: 0.6557\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 0.9034 - accuracy: 0.6894 - val_loss: 1.0816 - val_accuracy: 0.6552\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 0.8733 - accuracy: 0.7014 - val_loss: 1.1321 - val_accuracy: 0.6330\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 0.8704 - accuracy: 0.7018 - val_loss: 1.1109 - val_accuracy: 0.6485\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 85s 109ms/step - loss: 0.7593 - accuracy: 0.7387 - val_loss: 0.8093 - val_accuracy: 0.7321\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.7198 - accuracy: 0.7516 - val_loss: 0.7319 - val_accuracy: 0.7545\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.7010 - accuracy: 0.7588 - val_loss: 0.7318 - val_accuracy: 0.7534\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.6979 - accuracy: 0.7616 - val_loss: 0.6968 - val_accuracy: 0.7650\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.6804 - accuracy: 0.7656 - val_loss: 0.7274 - val_accuracy: 0.7546\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.6686 - accuracy: 0.7695 - val_loss: 0.6975 - val_accuracy: 0.7639\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 0.6642 - accuracy: 0.7710 - val_loss: 0.7445 - val_accuracy: 0.7489\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.6582 - accuracy: 0.7734 - val_loss: 0.6874 - val_accuracy: 0.7672\n",
      "Epoch 27/50\n",
      "782/782 [==============================] - 88s 112ms/step - loss: 0.6507 - accuracy: 0.7735 - val_loss: 0.7135 - val_accuracy: 0.7606\n",
      "Epoch 28/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.6397 - accuracy: 0.7795 - val_loss: 0.6751 - val_accuracy: 0.7710\n",
      "Epoch 29/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.6349 - accuracy: 0.7810 - val_loss: 0.7097 - val_accuracy: 0.7614\n",
      "Epoch 30/50\n",
      "782/782 [==============================] - 87s 111ms/step - loss: 0.6290 - accuracy: 0.7828 - val_loss: 0.7103 - val_accuracy: 0.7623\n",
      "Epoch 31/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.6232 - accuracy: 0.7849 - val_loss: 0.6818 - val_accuracy: 0.7691\n",
      "Epoch 32/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.6248 - accuracy: 0.7847 - val_loss: 0.7429 - val_accuracy: 0.7570\n",
      "Epoch 33/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.6237 - accuracy: 0.7826 - val_loss: 0.6738 - val_accuracy: 0.7715\n",
      "Epoch 34/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.6148 - accuracy: 0.7870 - val_loss: 0.6830 - val_accuracy: 0.7692\n",
      "Epoch 35/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.6087 - accuracy: 0.7920 - val_loss: 0.6287 - val_accuracy: 0.7876\n",
      "Epoch 36/50\n",
      "782/782 [==============================] - 87s 111ms/step - loss: 0.6058 - accuracy: 0.7924 - val_loss: 0.6272 - val_accuracy: 0.7868\n",
      "Epoch 37/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.6021 - accuracy: 0.7922 - val_loss: 0.6351 - val_accuracy: 0.7859\n",
      "Epoch 38/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5973 - accuracy: 0.7937 - val_loss: 0.6397 - val_accuracy: 0.7859\n",
      "Epoch 39/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5893 - accuracy: 0.7968 - val_loss: 0.6386 - val_accuracy: 0.7838\n",
      "Epoch 40/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5892 - accuracy: 0.7991 - val_loss: 0.6792 - val_accuracy: 0.7767\n",
      "Epoch 41/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5847 - accuracy: 0.7994 - val_loss: 0.6116 - val_accuracy: 0.7899\n",
      "Epoch 42/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5812 - accuracy: 0.7994 - val_loss: 0.6491 - val_accuracy: 0.7846\n",
      "Epoch 43/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5777 - accuracy: 0.8017 - val_loss: 0.6250 - val_accuracy: 0.7900\n",
      "Epoch 44/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5712 - accuracy: 0.8024 - val_loss: 0.6332 - val_accuracy: 0.7871\n",
      "Epoch 45/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5676 - accuracy: 0.8035 - val_loss: 0.6121 - val_accuracy: 0.7906\n",
      "Epoch 46/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5692 - accuracy: 0.8036 - val_loss: 0.6557 - val_accuracy: 0.7827\n",
      "Epoch 47/50\n",
      "782/782 [==============================] - 87s 111ms/step - loss: 0.5631 - accuracy: 0.8062 - val_loss: 0.6035 - val_accuracy: 0.7993\n",
      "Epoch 48/50\n",
      "782/782 [==============================] - 88s 113ms/step - loss: 0.5620 - accuracy: 0.8065 - val_loss: 0.6399 - val_accuracy: 0.7880\n",
      "Epoch 49/50\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.5586 - accuracy: 0.8069 - val_loss: 0.6568 - val_accuracy: 0.7813\n",
      "Epoch 50/50\n",
      "782/782 [==============================] - 87s 111ms/step - loss: 0.5559 - accuracy: 0.8086 - val_loss: 0.6218 - val_accuracy: 0.7904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x174c8dacdd8>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train,y_train,batch_size=64),\n",
    "                    validation_data=(x_val,y_val),validation_freq=1,\n",
    "                    epochs=50,\n",
    "                    callbacks=[keras.callbacks.ReduceLROnPlateau()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 568us/sample - loss: 0.6221 - accuracy: 0.7904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6221348830938339, 0.7904]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
